{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "# from models.multi_stage_sequenceencoder import multistageSTARSequentialEncoder, multistageLSTMSequentialEncoder\n",
    "# from models.networkConvRef import model_2DConv\n",
    "from eval import evaluate_fieldwise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input requriement files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from TransformerEncoder import TransformerEncoder\n",
    "from dataset import Dataset\n",
    "from utils.scheduled_optimizer import ScheduledOptim\n",
    "from utils.classmetric import ClassMetric"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data_path   = \"/Users/stevenzhu/Downloads/ZueriCrop.hdf5\"   # path to dataset\n",
    "gt_path     = '/Users/stevenzhu/Downloads/labels.csv'       # gt file path\n",
    "batchsize   = 4                                             # batch size\n",
    "workers     = 8                                             # number of dataset worker threads\n",
    "epochs      = 30                                            # epochs to train\n",
    "lr          = 0.001                                         # learning rate\n",
    "snapshot    = None                                          # load weights from snapshot\n",
    "checkpoint_dir = '/Users/stevenzhu/Downloads/'              # directory to save checkpoints\n",
    "weight_decay= 0.0001                                        # weight_decay\n",
    "hidden      = 64                                            # hidden dim\n",
    "layer       = 6                                             # num layer\n",
    "lrSC        = 2                                             # lrScheduler\n",
    "dropout     = 0.5                                           # dropout of CNN\n",
    "stage       = 3                                             # num stage\n",
    "clip        = 5                                             # grad clip\n",
    "seed        = 0                                             # random seed\n",
    "fold        = 1                                             # 5 fold\n",
    "cell        = \"star\"                                        # Cell type: main building block\n",
    "input_dim   = 4                                             # Input channel size\n",
    "apply_cm    = False                                         # apply cloud masking\n",
    "n_layers    = 6                                             # number of layers\n",
    "d_inner     = hidden*4\n",
    "n_heads     = 8                                             # \n",
    "fold_num    = None\n",
    "test_every_n_epochs = 1                                     # get test every n epochs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## main"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def main(\n",
    "#         datadir=None,\n",
    "#         batchsize=1,\n",
    "#         workers=12,\n",
    "#         epochs=1,\n",
    "#         lr=1e-3,\n",
    "#         snapshot=None,\n",
    "#         checkpoint_dir=None,\n",
    "#         weight_decay=0.0000,\n",
    "#         name='debug',\n",
    "#         layer=6,\n",
    "#         hidden=64,\n",
    "#         lrS=1,\n",
    "#         lambda_1=1,\n",
    "#         lambda_2=1,\n",
    "#         stage=3,\n",
    "#         clip=1,\n",
    "#         fold_num=None,\n",
    "#         gt_path=None,\n",
    "#         cell=None,\n",
    "#         dropout=None,\n",
    "#         input_dim=None,\n",
    "#         apply_cm=None\n",
    "#         ):\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Prepare dataset\n",
    "\n",
    "traindataset    = Dataset(data_path, 0., 'train', False, fold_num, gt_path, num_channel=input_dim, apply_cloud_masking=apply_cm)\n",
    "testdataset     = Dataset(data_path, 0., 'test', True, fold_num, gt_path, num_channel=input_dim, apply_cloud_masking=apply_cm)\n",
    "\n",
    "# number of classes\n",
    "nclasses     = traindataset.n_classes\n",
    "len_max_seq  = traindataset.max_obs\n",
    "\n",
    "# Loss weight\n",
    "LOSS_WEIGHT     = torch.ones(nclasses)\n",
    "LOSS_WEIGHT[0]  = 0\n",
    "\n",
    "# Class stage mappping\n",
    "s1_2_s3 = traindataset.l1_2_g\n",
    "s2_2_s3 = traindataset.l2_2_g\n",
    "\n",
    "# load dataset\n",
    "traindataloader = torch.utils.data.DataLoader(traindataset, batch_size=batchsize, shuffle=True, num_workers=workers)\n",
    "testdataloader = torch.utils.data.DataLoader(testdataset, batch_size=batchsize, shuffle=True, num_workers=workers)\n",
    "\n",
    "# model\n",
    "model =  TransformerEncoder(in_channels=input_dim, len_max_seq=len_max_seq,\n",
    "        d_word_vec=hidden, d_model=hidden, d_inner=d_inner,\n",
    "        n_layers=n_layers, n_head=n_heads, d_k=hidden//n_heads, d_v=hidden//n_heads,\n",
    "        dropout=dropout, nclasses=nclasses)\n",
    "\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"initialized {} model ({} parameters)\".format(model, pytorch_total_params))\n",
    "\n",
    "#loss\n",
    "loss = torch.nn.CrossEntropyLoss(weight=LOSS_WEIGHT)\n",
    "\n",
    "\n",
    "\n",
    "# CUDA\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    loss = loss.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=lr,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "#optimizer = ScheduledOptim(\n",
    "#        optim.Adam(\n",
    "#            filter(lambda x: x.requires_grad, model.parameters()),\n",
    "#            betas=(0.9, 0.98), eps=1e-09, weight_decay= weight_decay),\n",
    "#        model.d_model, args.warmup)\n",
    "\n",
    "## Learning rate scheduler\n",
    "# if lrS == 1:\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1, last_epoch=-1)\n",
    "# elif lrS == 2:\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, last_epoch=-1)\n",
    "# elif lrS == 3:\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5, last_epoch=-1)\n",
    "# else:\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5, last_epoch=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 0\n",
    "best_test_acc = 0\n",
    "#if snapshot is not None:\n",
    "#    checkpoint = torch.load(snapshot)\n",
    "#    network.load_state_dict(checkpoint['network_state_dict'])\n",
    "#    network_gt.load_state_dict(checkpoint['network_gt_state_dict'])\n",
    "#    optimizer.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "\n",
    "## fit model\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    print(\"\\nEpoch {}\".format(epoch))\n",
    "\n",
    "    train_epoch(traindataloader, model, optimizer, loss)\n",
    "\n",
    "    # call LR scheduler\n",
    "    #lr_scheduler.step()\n",
    "\n",
    "    # evaluate model\n",
    "    if epoch > 1 and epoch % 1 == 0:\n",
    "        print(\"\\n Eval on test set\")\n",
    "        stats = test_epoch(model, testdataloader, nclasses)\n",
    "        print(stats, epoch)\n",
    "\n",
    "        if checkpoint_dir is not None:\n",
    "            checkpoint_name = os.path.join(checkpoint_dir, name + '_epoch_' + str(epoch) + \"_model.pth\")\n",
    "            if test_acc > best_test_acc:\n",
    "                print('Model saved! Best val acc:', test_acc)\n",
    "                best_test_acc = test_acc\n",
    "                snapshot(checkpoint_name, optimizer, epoch)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def train_epoch(dataloader, model, optimizer, loss):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # builds a confusion matrix\n",
    "    # metric = ClassMetric(num_classes=self.nclasses)   \n",
    "\n",
    "    for iteration, data in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input, target_glob = data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "\n",
    "        logprobabilities, deltas, pts, budget = model.forward(input.transpose(1,2))\n",
    "        loss = F.nll_loss(logprobabilities, target[:, 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#        if isinstance(optimizer,ScheduledOptim):\n",
    "#            optimizer.step_and_update_lr()\n",
    "#        else:\n",
    "#            optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def test_epoch(model, dataloader, nclasses, epoch=None):\n",
    "    # sets the model to train mode: no dropout is applied\n",
    "    model.eval()\n",
    "\n",
    "    # builds a confusion matrix\n",
    "    #metric_maxvoted = ClassMetric(num_classes=self.nclasses)\n",
    "    metric = ClassMetric(num_classes=nclasses)\n",
    "    #metric_all_t = ClassMetric(num_classes=self.nclasses)\n",
    "\n",
    "    tstops = list()\n",
    "    predictions = list()\n",
    "    probas = list()\n",
    "    ids_list = list()\n",
    "    labels = list()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iteration, data in enumerate(dataloader):\n",
    "\n",
    "            input, target_glob = data\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                target_glob = target_glob.cuda()\n",
    "\n",
    "            logprobabilities, deltas, pts, budget = model.forward(inputs.transpose(1, 2))\n",
    "\n",
    "            loss = F.nll_loss(logprobabilities, target_glob[:, 0])\n",
    "\n",
    "            stats = dict(loss=loss,)\n",
    "\n",
    "            prediction = model.predict(logprobabilities)\n",
    "            t_stop = None\n",
    "\n",
    "            ## enter numpy world\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            label = target_glob.mode(1)[0].detach().cpu().numpy()\n",
    "            if t_stop is not None: t_stop = t_stop.cpu().detach().numpy()\n",
    "            if pts is not None: pts = pts.detach().cpu().numpy()\n",
    "            if deltas is not None: deltas = deltas.detach().cpu().numpy()\n",
    "            if budget is not None: budget = budget.detach().cpu().numpy()\n",
    "\n",
    "            if t_stop is not None: tstops.append(t_stop)\n",
    "            predictions.append(prediction)\n",
    "            labels.append(label)\n",
    "            probas.append(logprobabilities.exp().detach().cpu().numpy())\n",
    "\n",
    "            stats = metric.add(stats)\n",
    "\n",
    "            accuracy_metrics = metric.update_confmat(label,\n",
    "                                                        prediction)\n",
    "\n",
    "            stats[\"accuracy\"] = accuracy_metrics[\"overall_accuracy\"]\n",
    "            stats[\"mean_accuracy\"] = accuracy_metrics[\"accuracy\"].mean()\n",
    "\n",
    "            #for cl in range(len(accuracy_metrics[\"accuracy\"])):\n",
    "            #    acc = accuracy_metrics[\"accuracy\"][cl]\n",
    "            #    stats[\"class_{}_accuracy\".format(cl)] = acc\n",
    "\n",
    "            stats[\"mean_recall\"] = accuracy_metrics[\"recall\"].mean()\n",
    "            stats[\"mean_precision\"] = accuracy_metrics[\"precision\"].mean()\n",
    "            stats[\"mean_f1\"] = accuracy_metrics[\"f1\"].mean()\n",
    "            stats[\"kappa\"] = accuracy_metrics[\"kappa\"]\n",
    "            if t_stop is not None:\n",
    "                earliness = (t_stop.astype(float) / (inputs.shape[1] - 1)).mean()\n",
    "                stats[\"earliness\"] = metric.update_earliness(earliness)\n",
    "\n",
    "        stats[\"confusion_matrix\"] = copy.copy(metric.hist)\n",
    "        stats[\"targets\"] = targets.cpu().numpy()\n",
    "        stats[\"inputs\"] = inputs.cpu().numpy()\n",
    "        if deltas is not None: stats[\"deltas\"] = deltas\n",
    "        if pts is not None: stats[\"pts\"] = pts\n",
    "        if budget is not None: stats[\"budget\"] = budget\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if t_stop is not None: stats[\"t_stops\"] = np.hstack(tstops)\n",
    "    stats[\"predictions\"] = np.hstack(predictions) # N\n",
    "    stats[\"labels\"] = np.hstack(labels) # N\n",
    "    stats[\"probas\"] = np.vstack(probas) # NxC\n",
    "\n",
    "    return stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def snapshot(filename, optimizer, epoch):\n",
    "    model.save(\n",
    "        filename,\n",
    "        optimizer_state_dict=optimizer.state_dict(),\n",
    "        epoch=epoch)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('Capstone': conda)"
  },
  "interpreter": {
   "hash": "01d07a12c199c2baec792f1c4df1a2c7e01e4755325cc3c2c017772e38be4a45"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}